{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "52bcc284",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "class NaiveBayesClassifier:\n",
    "    \n",
    "    def driver(self,training,train_y,test,test_y):\n",
    "        \"\"\"\n",
    "        mini driver to call learn and predict function\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        training : Training dataset (x) DataFrame\n",
    "        train_y : Class(y) corresponding to training dataset DataFrame\n",
    "        test : Test dataset (x) DataFrame\n",
    "        test_y : Class(y) corresponding to testing dataset DataFrame\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pred_and_groundTruth :Array of 2 lists where the first list is algorithums predictions and the second is actual observerd class. \n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        pred_and_groundTruth = []\n",
    "        \n",
    "        # Turn test_y into list from dataframe\n",
    "        true_class = []\n",
    "        for i in test_y:\n",
    "            true_class.append(i)\n",
    "        \n",
    "        self.learn(training,train_y)\n",
    "        \n",
    "        pred_and_groundTruth.append(self.predict(test))\n",
    "        pred_and_groundTruth.append(true_class)\n",
    "        \n",
    "        return pred_and_groundTruth\n",
    "         \n",
    "    def learn(self,data,response):   \n",
    "        \"\"\"\n",
    "        Learns meta information about training dataset\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        data : Training dataset (x) DataFrame\n",
    "        response : Class(y) corresponding to training dataset DataFrame\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None.\n",
    "\n",
    "        \"\"\"\n",
    "        # meta information of data\n",
    "        self.num_samples = data.shape[0]\n",
    "        self.num_features = data.shape[1]\n",
    "        self.num_classes = list(np.unique(response))\n",
    "            \n",
    "        # Count of each class\n",
    "        self.cls_dict = {}\n",
    "        for cls in self.num_classes:\n",
    "            self.cls_dict.update({cls: np.count_nonzero(response == cls)})\n",
    "        \n",
    "        self.feature_likelyhood = self.calc_feature_likelyhood(data,response)\n",
    "        \n",
    "    def predict(self,data):\n",
    "        \"\"\"\n",
    "        Returns predictions for test dataset\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        data : Test dataset(x) Datafrane\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        predictions : List of predicted classes based on input features\n",
    "\n",
    "        \"\"\"\n",
    "        alpha = 1\n",
    "        predictions = []\n",
    "         \n",
    "        for i in data.iterrows():    # Iterate through rows\n",
    "            tmp = []\n",
    "            for cls in range(len(self.num_classes)): # Iterate through number of classes in dataset\n",
    "                \n",
    "                feature_index = 0\n",
    "                probability = 1\n",
    "                               \n",
    "                for feature in i[1]:        # check if feature is in likelyhood dictionary\n",
    "                    if self.feature_likelyhood[cls][feature_index].get(feature) is None:\n",
    "                        probability *= alpha / ( self.cls_dict.get(self.num_classes[cls]) + alpha * len(self.num_classes))  # laplace smoothing\n",
    "                    else:\n",
    "                        probability *= self.feature_likelyhood[cls][feature_index].get(feature)\n",
    "                    \n",
    "                    feature_index +=1\n",
    "                    \n",
    "                tmp.append((self.cls_dict.get(self.num_classes[cls]) / self.num_samples)  * probability)\n",
    "                \n",
    "            predictions.append(self.num_classes[tmp.index(max(tmp))]) \n",
    "        \n",
    "        return predictions\n",
    "        \n",
    "        \n",
    "    def calc_feature_likelyhood(self,data,response):     \n",
    "        \"\"\"\n",
    "        Calculates feature probability matrix of training data with laplace smoothing\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        data : Training dataset(x) DataFrame\n",
    "        response : Class(y) corresponding to training dataset DataFrame\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        likelyHood_array : List of n probability matricies. where n is number of classes \n",
    "\n",
    "        \"\"\"\n",
    "        alpha = 1\n",
    "        split_data = self.calc_lk(data,response)\n",
    "        likelyHood_array = []\n",
    "        \n",
    "        for s in split_data: # array s in split data \n",
    "            tmp = []\n",
    "            for i in s:    # columns in s \n",
    "                \n",
    "                likelyhood = {}\n",
    "                for j,value in s[i].items():   # Iterates through col and counts number of unique values\n",
    "                    \n",
    "                    if value in likelyhood.keys():                      \n",
    "                        likelyhood[value] += 1\n",
    "                    else:\n",
    "                        likelyhood[value] = 1 \n",
    "                \n",
    "                for count in likelyhood.keys(): # Iterates through dictionary keys and divides by num_observations\n",
    "                    likelyhood[count] = (likelyhood.get(count) + alpha) / (s.shape[0] +alpha * len(self.num_classes))         # laplace smoothing \n",
    "                \n",
    "                tmp.append(likelyhood)\n",
    "            likelyHood_array.append(tmp)\n",
    "        \n",
    "        return likelyHood_array\n",
    "\n",
    "    def calc_lk(self,data,response):\n",
    "        \"\"\"\n",
    "        Splits trainging dataset by class. Helper function to calc_feature_likelyhood. \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        data : Training dataset(x) DataFrame\n",
    "        response : Class(y) corresponding to training dataset DataFrame\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        list of n DataFrames. Where n is number of classes.\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        split_data = []\n",
    "        \n",
    "        for x in range(len(self.num_classes)): # adds n number of DataFrames to split_data \n",
    "            \n",
    "            split_data.append(pd.DataFrame())\n",
    "        \n",
    "        ind_count = 0\n",
    "        for cls in self.num_classes:\n",
    "            tmp = []\n",
    "            for i,y in response.items():\n",
    "                if y == cls: \n",
    "                    tmp.append(data.iloc[i])\n",
    "                    \n",
    "            split_data[ind_count] = pd.DataFrame(tmp)\n",
    "            ind_count +=1\n",
    "        return split_data\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6641caa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['D1',\n",
       "  'D1',\n",
       "  'D1',\n",
       "  'D1',\n",
       "  'D1',\n",
       "  'D1',\n",
       "  'D1',\n",
       "  'D1',\n",
       "  'D1',\n",
       "  'D2',\n",
       "  'D2',\n",
       "  'D2',\n",
       "  'D2',\n",
       "  'D2',\n",
       "  'D2',\n",
       "  'D2',\n",
       "  'D2',\n",
       "  'D2',\n",
       "  'D2',\n",
       "  'D3',\n",
       "  'D3',\n",
       "  'D3',\n",
       "  'D3',\n",
       "  'D3',\n",
       "  'D3',\n",
       "  'D3',\n",
       "  'D3',\n",
       "  'D3',\n",
       "  'D3',\n",
       "  'D4',\n",
       "  'D4',\n",
       "  'D4',\n",
       "  'D4',\n",
       "  'D4',\n",
       "  'D4',\n",
       "  'D4',\n",
       "  'D4',\n",
       "  'D4',\n",
       "  'D4',\n",
       "  'D4',\n",
       "  'D4',\n",
       "  'D4',\n",
       "  'D4',\n",
       "  'D4',\n",
       "  'D4',\n",
       "  'D4'],\n",
       " ['D1',\n",
       "  'D1',\n",
       "  'D1',\n",
       "  'D1',\n",
       "  'D1',\n",
       "  'D1',\n",
       "  'D1',\n",
       "  'D1',\n",
       "  'D1',\n",
       "  'D2',\n",
       "  'D2',\n",
       "  'D2',\n",
       "  'D2',\n",
       "  'D2',\n",
       "  'D2',\n",
       "  'D2',\n",
       "  'D2',\n",
       "  'D2',\n",
       "  'D2',\n",
       "  'D3',\n",
       "  'D3',\n",
       "  'D3',\n",
       "  'D3',\n",
       "  'D3',\n",
       "  'D3',\n",
       "  'D3',\n",
       "  'D3',\n",
       "  'D3',\n",
       "  'D3',\n",
       "  'D4',\n",
       "  'D4',\n",
       "  'D4',\n",
       "  'D4',\n",
       "  'D4',\n",
       "  'D4',\n",
       "  'D4',\n",
       "  'D4',\n",
       "  'D4',\n",
       "  'D4',\n",
       "  'D4',\n",
       "  'D4',\n",
       "  'D4',\n",
       "  'D4',\n",
       "  'D4',\n",
       "  'D4',\n",
       "  'D4']]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"C:/Users/Noah Metzger/GitRepo/Machine-Learning----Project-1/Data/soybean-small.csv\")\n",
    "test = pd.DataFrame(data = data)\n",
    "\n",
    "\n",
    "nd = NaiveBayesClassifier()\n",
    "\n",
    "nd.driver(test[test.columns[0:35]],test[test.columns[35]],test[test.columns[0:35]],test[test.columns[35]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e816c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf5089f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b4d2c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15feaed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d0ad20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf1bdde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143a5ebf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa400b98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0481188",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06982420",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e025257",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c489ccf5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
